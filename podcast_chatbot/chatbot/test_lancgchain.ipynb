{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chat_history = [{'type': 'ai', 'data': {'content': \"<p>The key points discussed in the podcast include:</p>\\n<ol>\\n  <li><strong>Encounters with Suspicious Individuals:</strong> The narrator shares unsettling experiences, such as encountering a man in a trench coat late at night, emphasizing the importance of trusting one's intuition and being cautious around shady individuals.</li>\\n  <li><strong>Cautionary Tale about Francis:</strong> The podcast warns about the dangers of engaging with people who may be hiding something, using the story of Francis as an example. It highlights the significance of being mindful of the company one keeps and the potential risks involved.</li>\\n  <li><strong>Personal Safety:</strong> The podcast underscores the importance of personal safety, especially for college students and young individuals, advising listeners to be vigilant about who they allow into their lives and to prioritize their safety in various situations.</li>\\n</ol>\\n<p>If you have any more specific questions or need further details on these key points, feel free to ask!</p>\", 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': None, 'example': False, 'tool_calls': [], 'invalid_tool_calls': []}}, {'type': 'human', 'data': {'content': 'what are key points discussed in this podcasrt', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': None, 'example': False}}, {'type': 'ai', 'data': {'content': \"<p>I'm sorry, but the context provided does not contain specific details about the podcast itself or its production. If you have any questions related to the content within the podcast or need clarification on any specific information mentioned in the context, feel free to ask, and I'll be happy to provide you with relevant details.</p>\", 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': None, 'example': False, 'tool_calls': [], 'invalid_tool_calls': []}}, {'type': 'human', 'data': {'content': 'Tell me few interesting facts about this podcast', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': None, 'example': False}}, {'type': 'ai', 'data': {'content': \"<p>I'm here and ready to assist you with any questions you have about the podcast content. Feel free to ask anything related to the podcast, and I'll provide you with detailed and informative answers. Let me know how I can help you today!</p>\", 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': None, 'example': False, 'tool_calls': [], 'invalid_tool_calls': []}}, {'type': 'human', 'data': {'content': 'HOW ARE YOU', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': None, 'example': False}}, {'type': 'ai', 'data': {'content': '<h2>Podcast Summary:</h2>\\n\\n<p>The podcast recounts a series of unsettling encounters experienced by the narrator, including a disturbing incident with a man in a trench coat while walking to a store late at night. The narrator also shares a cautionary tale about a person named Francis, highlighting the importance of being cautious around shady individuals. The podcast emphasizes the significance of being mindful of who you allow into your life and staying safe in various situations.</p>\\n\\n<p>If you have any specific questions about the podcast content, feel free to ask!</p>', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': None, 'example': False, 'tool_calls': [], 'invalid_tool_calls': []}}, {'type': 'human', 'data': {'content': 'Please provide brief summary of the podcast', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': None, 'example': False}}, {'type': 'ai', 'data': {'content': \"<p>Hello! How can I assist you today with any questions or information related to the podcast content? Feel free to ask anything you'd like to know!</p>\", 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': None, 'example': False, 'tool_calls': [], 'invalid_tool_calls': []}}, {'type': 'human', 'data': {'content': 'Hi', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': None, 'example': False}}, {'type': 'ai', 'data': {'content': \"<h2>Welcome to PodQuest!</h2>\\n<p>I'm here and ready to assist you with any questions you have about the podcast content. Feel free to ask anything related to the podcast, and I'll provide you with detailed and informative answers. Let me know how I can help you today!</p>\", 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': None, 'example': False, 'tool_calls': [], 'invalid_tool_calls': []}}, {'type': 'human', 'data': {'content': 'How are you', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': None, 'example': False}}, {'type': 'ai', 'data': {'content': \"<html>\\n<head>\\n    <title>PodQuest Response</title>\\n</head>\\n<body>\\n    <h1>Hello! How can I assist you today with any questions or information related to the podcast content?</h1>\\n    <p>Feel free to ask anything you'd like to know!</p>\\n</body>\\n</html>\", 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': None, 'example': False, 'tool_calls': [], 'invalid_tool_calls': []}}, {'type': 'human', 'data': {'content': 'Hi', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': None, 'example': False}}, {'type': 'ai', 'data': {'content': '<h2>Podcast Summary:</h2>\\n\\n<p>The podcast recounts a series of unsettling encounters experienced by the narrator, including a disturbing incident with a man in a trench coat while walking to a store late at night. The narrator also shares a cautionary tale about a person named Francis, highlighting the importance of being cautious around shady individuals. The podcast emphasizes the significance of being mindful of who you allow into your life and staying safe in various situations.</p>\\n\\n<p>If you have any specific questions about the podcast content, feel free to ask!</p>', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': None, 'example': False, 'tool_calls': [], 'invalid_tool_calls': []}}, {'type': 'human', 'data': {'content': 'Please provide a brief summary of the podcast.', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': None, 'example': False}}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'human',\n",
       " 'data': {'content': 'what are key points discussed in this podcasrt',\n",
       "  'additional_kwargs': {},\n",
       "  'response_metadata': {},\n",
       "  'type': 'human',\n",
       "  'name': None,\n",
       "  'id': None,\n",
       "  'example': False}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chat_history[0]['data']['content']\n",
    "# chat_history[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pytube import YouTube\n",
    "# video_url = \"https://www.youtube.com/watch?v=J0gMTpdZnvI\"\n",
    "# print(\"Downloading audio from: \", video_url)\n",
    "# yt = YouTube(video_url)\n",
    "# # yt.title = title\n",
    "# yt.streams.filter(only_audio=True).first().download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # tasks.py\n",
    "\n",
    "# from yt_dlp import YoutubeDL\n",
    "\n",
    "\n",
    "# ydl_opts = {\n",
    "#     'format': 'bestaudio/best',\n",
    "#     'outtmpl': f'./sample.%(ext)s',\n",
    "#     'postprocessors': [{\n",
    "#         'key': 'FFmpegExtractAudio',\n",
    "#         'preferredcodec': 'mp3',\n",
    "#         'preferredquality': '192',\n",
    "#     }],\n",
    "# }\n",
    "# with YoutubeDL(ydl_opts) as ydl:\n",
    "#     ydl.download([video_url])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import redis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# redis_client = redis.StrictRedis.from_url(\"redis://localhost:6379/0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# redis_client.keys(\"*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# redis_client.lrange(\"message_store:Skull0412_13_session\", 0, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "__import__('pysqlite3')\n",
    "import sys\n",
    "sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')\n",
    "# from django.conf import settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone, ServerlessSpec, PodSpec\n",
    "import time\n",
    "import os\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "BASE_DIR = Path('./').resolve().parent\n",
    "def load_config():\n",
    "    with open(os.path.join(BASE_DIR.parent, 'keys.yaml'), 'r') as file:\n",
    "        config = yaml.safe_load(file)\n",
    "        return config\n",
    "\n",
    "config = load_config()\n",
    "pinecone_api_key = config['api_keys']['PINECONE_API_KEY']\n",
    "use_serverless = True\n",
    "pc = Pinecone(api_key=pinecone_api_key)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {'Skull0412_21': {'vector_count': 14}},\n",
       " 'total_vector_count': 14}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = pc.Index('podcasts')  \n",
    "index.describe_index_stats() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_serverless:  \n",
    "    spec = ServerlessSpec(cloud='aws', region='us-east-1')  \n",
    "else:  \n",
    "    # if not using a starter index, you should specify a pod_type too  \n",
    "    spec = PodSpec()  \n",
    "# check for and delete index if already exists  \n",
    "index_name = 'podcasts'  \n",
    "if index_name in pc.list_indexes().names():  \n",
    "    pc.delete_index(index_name)  \n",
    "# create a new index  \n",
    "pc.create_index(  \n",
    "    index_name,  \n",
    "    dimension=1536,  # dimensionality of text-embedding-ada-002  \n",
    "    metric='cosine',  \n",
    "    spec=spec  \n",
    ")  \n",
    "# wait for index to be initialized  \n",
    "while not pc.describe_index(index_name).status['ready']:  \n",
    "    time.sleep(1)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {},\n",
       " 'total_vector_count': 0}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = pc.Index('podcasts')  \n",
    "index.describe_index_stats() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of splits: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parent run 1898d06c-f6df-4f13-b82a-1510fa098e32 not found for run 21f1c45a-909f-4b8d-abe1-0d9525e5c201. Treating as a root run.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain.chains import create_history_aware_retriever, create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory, RedisChatMessageHistory\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = config['api_keys']['OPENAI_API_KEY']\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = config['api_keys']['LANGCHAIN_API_KEY']\n",
    "os.environ[\"PINECONE_API_KEY\"] = config['api_keys']['PINECONE_API_KEY']\n",
    "os.environ[\"PINECONE_INDEX_NAME\"] = \"podcasts\"\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0) \n",
    "\n",
    "loader = TextLoader(\"/home/gaurav/Documents/Project/podcast_chatbot/media/podcasts/Skull0412/58_mins/58_mins.txt\")\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "print(f\"Length of splits: {len(splits)}\")\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vectorstore = PineconeVectorStore(index_name=\"podcasts\", embedding=embeddings)\n",
    "vectorstore.add_documents(splits, namespace=\"skull0412\")\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"namespace\": \"skull0412\"})\n",
    "output_parser = StrOutputParser()\n",
    "### Contextualize question ###\n",
    "contextualize_q_system_prompt = \"\"\"\n",
    "    As the initial step in the PodQuest system, your task is to prepare the user's latest question by making it clear and self-contained. This involves utilizing the chat history to provide contextually relevant and accurate reformulations. Here’s how you should handle the user's latest question:\n",
    "\n",
    "    1. **Contextual Understanding:** Carefully review the chat history to understand the context of the ongoing conversation. Use this context to fully comprehend the user's latest question.\n",
    "\n",
    "    2. **Reformulate for Clarity:** If the latest user question references previous parts of the conversation and is not standalone, reformulate it to make it clear and self-contained. Ensure that the reformulated question maintains the original intent and meaning.\n",
    "\n",
    "    3. **Direct Response:** Provide only the reformulated question as the output. Do not include any context summary or additional information.\n",
    "\n",
    "    4. **No Redundancy:** If the user's latest question is already clear and self-contained, return it as is without any modifications.\n",
    "\n",
    "    5. **Example:**\n",
    "    - **Chat History:** \n",
    "        - User: \"Can you tell me about the new AI technique mentioned?\"\n",
    "        - PodQuest: \"Sure! The podcast mentions a new AI technique called X, which involves [detailed explanation].\"\n",
    "        - User: \"How is it applied in real-world scenarios?\"\n",
    "    - **Reformulated Question:** \"How is the new AI technique called X, mentioned earlier, applied in real-world scenarios?\"\n",
    "\n",
    "    By following these guidelines, you will ensure that each user question is clear, self-contained, and contextually relevant, enabling accurate and helpful responses in subsequent steps of the PodQuest system.\n",
    "    \"\"\"\n",
    "contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", contextualize_q_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "history_aware_retriever = create_history_aware_retriever(\n",
    "    llm, retriever, contextualize_q_prompt\n",
    ")\n",
    "\n",
    "\n",
    "### Answer question ###\n",
    "qa_system_prompt = \"\"\"\n",
    "    You are PodQuest, an expert chatbot designed to assist users with questions about podcast content. You use a Retrieval-Augmented Generation (RAG) model to provide accurate and detailed responses based on the context retrieved from the podcasts. Here’s how you should behave:\n",
    "\n",
    "    1. Expert and Friendly: Always maintain a friendly and professional demeanor. You are an expert on the podcast content and should provide detailed and informative answers.\n",
    "\n",
    "    2. Contextual Responses: Answer each user's question directly using the context provided. Avoid giving irrelevant information. Ensure that your answers are concise (r detailed if user asked for) and relevant to the context retrieved from the podcast.\n",
    "\n",
    "    3. Engaging Conversation: Strive to keep the conversation engaging. Provide additional relevant information when appropriate and encourage users to ask more questions if they need further clarification.\n",
    "\n",
    "    4. Handling Irrelevant Questions:\n",
    "    - If a user asks an irrelevant question or a question outside the scope of the podcast, politely let them know that you can only answer questions related to the podcast content.\n",
    "    - Suggest they ask questions specific to the podcast to get the most accurate information.\n",
    "\n",
    "    5. No Context Available:\n",
    "    - If the context does not contain the information needed to answer a question, let the user know that the specific detail is not available in the current podcast.\n",
    "    - Offer to help with another question.\n",
    "    \n",
    "    By following these guidelines, you will ensure users have a helpful and engaging experience while interacting with you. Always aim to provide the most accurate and contextually relevant information available. Good luck, PodQuest!\n",
    "    Here is the context retrieved from the podcast:\n",
    "{context}\"\"\"\n",
    "qa_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", qa_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "question_answer_chain = create_stuff_documents_chain(llm, qa_prompt)\n",
    "\n",
    "rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)\n",
    "\n",
    "beautify_system_prompt = \"\"\"\n",
    "Your task is to format the response generated by PodQuest into a clean, readable HTML format. This involves converting lists, points, and other elements into their appropriate HTML tags to enhance readability. Ensure the response is presented in a user-friendly and visually appealing manner.\n",
    "Make sure to not change the content of the response, only the formatting. Follow this rule very strictly!!!\n",
    "Example:\n",
    "- Response: \"The new AI technique involves several steps: data preprocessing, model training, and evaluation. Each step has specific requirements.\"\n",
    "- Formatted Response: \"<p>The new AI technique involves several steps:</p><ul><li>Data preprocessing</li><li>Model training</li><li>Evaluation</li></ul><p>Each step has specific requirements.</p>\"\n",
    "\"\"\"\n",
    "beautify_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", beautify_system_prompt),\n",
    "        (\"human\", \"{answer}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "full_chain = rag_chain | (beautify_prompt | llm) | {\"formatted_answer\": output_parser}\n",
    "# beautify_chain = SimpleChain(\n",
    "#     input_key=\"answer\",\n",
    "#     output_key=\"formatted_answer\",\n",
    "#     llm=ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0),\n",
    "#     prompt_template=beautify_prompt,\n",
    "# )\n",
    "\n",
    "# # Combine chains\n",
    "# full_chain = SimpleChain(\n",
    "#     input_key=\"input\",\n",
    "#     output_key=\"final_output\",\n",
    "#     sub_chains=[rag_chain, beautify_chain],\n",
    "# )\n",
    "\n",
    "def get_message_history(session_id: str) -> RedisChatMessageHistory:\n",
    "    return RedisChatMessageHistory(session_id, url=\"redis://localhost:6379/0\")\n",
    "\n",
    "conversational_rag_chain = RunnableWithMessageHistory(\n",
    "    full_chain,\n",
    "    get_message_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    "    output_messages_key=\"formatted_answer\",\n",
    ")\n",
    "\n",
    "response = conversational_rag_chain.invoke(\n",
    "    {\"input\": \"Give a list of important points from the podcast.\"},\n",
    "    config={\n",
    "        \"configurable\": {\"session_id\": \"abc123\"}\n",
    "    },  # constructs a key \"abc123\" in `store`.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'formatted_answer': \"<p>Certainly! Here are some important points from the podcast:</p>\\n<ol>\\n  <li>When presenting remotely, it's essential to maintain engagement and variety to connect with your audience effectively.</li>\\n  <li>For expert witness testimony or any speaking situation, it's recommended to identify important themes and have concrete evidence to support them rather than relying on memorized terms.</li>\\n  <li>Taking breaks during a presentation to interact with the audience and apply the content can enhance engagement and understanding.</li>\\n  <li>Utilizing tools like Google Docs can help in monitoring audience engagement and participation during a remote presentation.</li>\\n</ol>\\n<p>These points highlight the significance of engagement, preparation, and interaction in effective communication, especially in remote settings. If you have any more questions or need further details on any of these points, feel free to ask!</p>\"}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parent run 5431bc36-97cf-47ce-81c2-abfb48bb1f7a not found for run 62cafee7-4666-494c-ac15-6fa334c7446c. Treating as a root run.\n",
      "Error in RootListenersTracer.on_chain_end callback: KeyError('answer')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<ul>\\n    <li>Introduction to the topic of artificial intelligence</li>\\n    <li>Discussion on the impact of AI on various industries</li>\\n    <li>Explanation of machine learning algorithms</li>\\n    <li>Importance of data quality in AI applications</li>\\n    <li>Challenges and limitations of current AI technologies</li>\\n</ul>'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversational_rag_chain.invoke(\n",
    "    {\"input\": \"Give a list of important points from the podcast.\"},\n",
    "    config={\n",
    "        \"configurable\": {\"session_id\": \"abc123\"}\n",
    "    },  # constructs a key \"abc123\" in `store`.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {'skull0412': {'vector_count': 49}},\n",
       " 'total_vector_count': 49}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = pc.Index(index_name)  \n",
    "index.describe_index_stats() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parent run dce6ded8-91ef-4380-805b-e61f71faeaf8 not found for run 18762578-aa17-4773-84d9-b3aa39c02777. Treating as a root run.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I'm here and ready to help. How can I assist you today?\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversational_rag_chain.invoke(\n",
    "    {\"input\": \"Hi, how are you?\"},\n",
    "    config={\n",
    "        \"configurable\": {\"session_id\": \"abc123\"}\n",
    "    },  # constructs a key \"abc123\" in `store`.\n",
    ")[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parent run dca8b972-9c67-4c64-965e-ac040ce6c3fd not found for run a03b748f-a0ec-40ba-8442-992d8f5dd039. Treating as a root run.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The podcast discusses the recent military operation in Gaza, focusing on the conflict between the Israeli government and Hamas. The conversation touches on the lack of alignment between the two parties, the potential long-term effects of the conflict, and the implications for future events such as diplomatic trips and political gatherings.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversational_rag_chain.invoke(\n",
    "    {\"input\": \"Give me the summary of the podcast.\"},\n",
    "    config={\n",
    "        \"configurable\": {\"session_id\": \"abc123\"}\n",
    "    },  # constructs a key \"abc123\" in `store`.\n",
    ")[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {'skull0412': {'vector_count': 49}},\n",
       " 'total_vector_count': 49}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = pc.Index(index_name)\n",
    "index.describe_index_stats() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parent run b8448b42-15b5-4db1-8dd8-da7b28505d35 not found for run 1fe3d438-5c2f-4ee2-ad4a-0c6a74d994cc. Treating as a root run.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hamas has faced significant damage to its military capabilities, but they are still able to continue launching rockets against Israel. The Israeli government and many in Israel want Hamas destroyed, including their leadership and fighters, but they have not achieved that military outcome yet.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversational_rag_chain.invoke(\n",
    "    {\"input\": \"Give me answer to my previous question again?\"},\n",
    "    config={\n",
    "        \"configurable\": {\"session_id\": \"abc123\"}\n",
    "    },  # constructs a key \"abc123\" in `store`.\n",
    ")[\"answer\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
